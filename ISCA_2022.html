<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
	
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Fearless Steps Challenge: Phase 4</title>
<link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
	<link rel="icon" href="favicon.ico" type="image/x-icon">
	<link rel="stylesheet" href="css/styles.css"> 
	
</head>
<body>
<div class="page-wrapper">
<div class="top-banner">
<h1> Fearless Steps Challenge:<br>Phase IV</h1>


</div>
<div class="top-top-nav">

<div class="tabs">
	<div class="tabs-img">
		<img src="images/top-1.jpg" alt="Fearless Engineering" id="fearless">
		
		</div>
	<div class="links">
		<a href="#ISCA_2022"><u><strong>Special Session</strong></u></a><br>
		
		<div class="link_list">
			
			<a href='#Session_Format'>Session Format</a><br>
			<!--<a href="#Track_1">Baseline</a><br>
			<a href="#Track_1">References</a><br>-->
		
		</div>
		
		
	</div>
</div>
<div class="image-top" >
<img src="images/Logos.png" alt="" id="logo">
</div>
<div class="top-nav">
		<a  href="index.html">Home</a>

		<a  href="Data.html">FSC-4 Data</a>
		
		<a href="SAD.html">SAD</a>
		<a href="DIAR.html">DIAR</a>
		<a href="SID.html">SID</a>
		<a href="SV.html">SV</a>
		<a href="ASR.html">ASR</a>
		<a href="Conv.html">Topic Detection</a>
		<a class="active" href="ISCA_2022.html">ISCA 2022</a>
		
	</div>
     <div class="article" id="ISCA_2022">
<h2>Interspeech Special Session</h2>

		<p>CRSS-UTDallas held the First Fearless Steps Challenge in 2019. The Challenge was held from February to June 2019, in which 16 organizations competed for the 5 Challenge Tasks, submitting 116 systems. The Second Fearless Steps Challenge (Phase-02) held form February to May 2020 had 17 teams competing with 111 system submissions. For the first two Fearless Steps Challenges released in Phases, the 100-hour audio used for the Challenge remained the same, while the supervised data size and Tasks evolved. The Phase-01 focused on developing unsupervised and semi-supervised systems. Thus, only 20 hours of development data was fully transcribed (in addition to the 20-hour blind evaluation set). As a natural progression, Phase-02 focused on the development of supervised systems, with 60 hours of manually transcribed training set, 20 hours each allocated for development and evaluation sets. Improvements on the Challenge Format proposed in Phase-02 were successful.<br> For Phase-03, 5 hours of an unseen Apollo-11 channel data was presented to test system robustness towards changes in channel characteristics. 5 additional hours of Apollo-13 mission data was provided to test the system’s ability to generalize performance over entirely separate missions.<br> We propose to continue this trend for the Phase-04, leveraging the experiences from the first three challenges, while restoring the most successful aspects of Phase-01, Phase-02, and Phase-03 based on community feedback. Due to the overwhelming increase in deep learning systems submissions outperforming the other machine learning strategies for the First Challenge, new and improved DNN based baseline systems will also be provided to the community to motivate robust system development on naturalistic data. The improved addition to Phase-04 of this Challenge are: 
		<ul>
		<li>Speaker Verification task using previously unseen speakers extracted from the Apollo-8 Mission</li><br> 
		<li>Topic Detection task to evaluate language understanding in naturalistic speech through detection of conversational “hot-spots”</li><br> 
		<li>10 additional hours of previously unreleased Apollo-8 data for evaluation of inter-mission robustness., which will have multiple factors different from the Apollo-11 Mission data, which the systems will primarily use to train.</li><br> 
		</ul>

The major advantage we have for the Phase-04 of the Challenge are the learnings from the Phase-01, Phase-02, and Phase-03 from which we have been be able to use the existing infrastructure to further improve the Challenge Tasks, Baselines and Evaluation Plan. The Interspeech-2022 Special Session will be a great opportunity to reflect on the evolution of the Challenge and Systems performances in the past 4 years and focus on the promising future directions for extracting knowledge from massive naturalistic audio.</p>
<div class="sub-article" id="#Session_Format">
<h3>Session Format</h3>

        				
        				<p> The objective of the Special Session is to provide a forum for advancing speech technology and research on massive naturalistic data. In addition, the special session is also intended to provide a mechanism for discussions on challenge task evaluations and innovative solutions to these tasks.

The session will consist of 15-minute oral talks with: (i) an overview talk of the Fearless Steps corpus, baseline systems, performance metrics for each of the Six Challenge Tasks; followed by (ii)

oral presentations on the top two best performing systems evaluated for each Challenge Task. In addition, there will be a corresponding poster session for all submissions not in the top two positions. Finally, there will be a (20-minute) panel discussion, with panelists chosen among the authors of the best rated and most controversial papers. The discussion will be moderated by the organizers and the outcomes will be summarized in a paper submitted for publication (conference, newsletter, or magazine</p>

</div>
  						


</div>
</div>
</div>

</body>


</html>